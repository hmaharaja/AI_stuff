{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hmaharaja/AI_stuff/blob/Steel-defect-classification/Stage1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhvJvwG2jYuq",
        "colab_type": "text"
      },
      "source": [
        "#Setup and Architecture\n",
        "\n",
        "Here we will find the following sections: \n",
        "   1. Import Section\n",
        "   2. Defining the training/accuracy functions \n",
        "   3. Dataset Generation\n",
        "   4. Training Stage 1 AlexNet model\n",
        "   5. Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiikkWY4pyy5",
        "colab_type": "text"
      },
      "source": [
        "#FORMATTING NOTES:\n",
        "\n",
        "1. **Input size for images is:** 224 by 224\n",
        "2. All images should be in greyscale (With channel dimension included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAr2ALkUn0qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Section\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "import scipy.signal as sg\n",
        "from PIL import Image, ImageDraw\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import torch.optim as optim #for gradient descent\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms, utils, models\n",
        "\n",
        "import csv\n",
        "import seaborn as sn\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "from scipy import ndimage, misc\n",
        "import itertools\n",
        "from skimage import io, transform\n",
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ErXBq5GtuR7",
        "colab_type": "text"
      },
      "source": [
        "#20 Samples Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFmcZ1Do76y",
        "colab_type": "code",
        "outputId": "befcfc46-406d-4286-c880-abb37b9b22be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfznVHN9tzK3",
        "colab_type": "text"
      },
      "source": [
        "#Define Training and Accuracy Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeGPTZbpXiMO",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data_loader, useGPU=True):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "        #To Enable GPU Usage\n",
        "        if useGPU and torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            model = model.cuda()\n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF5tQuGAnxJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_data, val_data, batch_size=64, num_epochs=1, learning_rate=0.01, useGPU=True):\n",
        "    \n",
        "    #Put data in data loaders\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=0, shuffle=False)\n",
        "    val_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=0, shuffle=False)\n",
        "   \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
        "    #optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    if useGPU and torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        print(\"Training on GPU\")\n",
        "   \n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_data_loader):\n",
        "          #To Enable GPU Usage\n",
        "          if useGPU and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "          \n",
        "          out = model(imgs)             # forward pass\n",
        "\n",
        "          loss = criterion(out, labels) # compute the total loss\n",
        "          loss.backward()               # backward pass (compute parameter updates)\n",
        "          optimizer.step()              # make the updates for each parameter\n",
        "          optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "          # save the current training information\n",
        "          iters.append(n)\n",
        "          losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "          train_acc.append(get_accuracy(model, train_data_loader, useGPU)) # compute training accuracy \n",
        "          val_acc.append(get_accuracy(model, val_data_loader, useGPU))  # compute validation accuracy\n",
        "          print(\"Iteration: \", str(n), \"| Train Loss: \", losses[n], \"| Train Accuracy: \", train_acc[n], \"| Validation Accuracy: \", val_acc[n])\n",
        "          n += 1\n",
        "        #print((\"Epoch {}: Train loss: {}, \"+\"Train accuracy: {}\"+\"| \"+\"Validation accuracy: {}\").format(epoch + 1,losses[epoch],\n",
        "                                                                                                        #train_acc[epoch], val_acc[epoch]))\n",
        "            \n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(model.name,\n",
        "                                                    batch_size,\n",
        "                                                    str(learning_rate).replace('.', '-'),\n",
        "                                                    epoch)\n",
        "        torch.save(model.state_dict(), model_path + \".pth\")         \n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRODTdcxOnF8",
        "colab_type": "text"
      },
      "source": [
        "# Split train Data into 1 and 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJIpykewm0_",
        "colab_type": "code",
        "outputId": "d7908e95-27a9-455c-bed5-88a4f74eefa7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "source": [
        "#Link to competition: https://www.kaggle.com/c/severstal-steel-defect-detection/overview\n",
        "#Upload the Kaggle JSON file (download it from the drive to your computer first)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9adf0334-88c1-4b4d-b8c1-c4fecdf75d58\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9adf0334-88c1-4b4d-b8c1-c4fecdf75d58\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-21dc3c638f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: TypeError: Cannot read property '_uploadFiles' of undefined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9f4PxF5wnvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mount the kaggle.json file\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188R2ubXw3ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Extract required files\n",
        "!kaggle competitions download -c severstal-steel-defect-detection -q\n",
        "!unzip -q train.csv.zip\n",
        "!unzip -q train_images.zip -d train_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOR3DErY0WW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the dataset and list of filenames\n",
        "\n",
        "def removeDuplicates(lst):\n",
        "    #Remove duplicate values from a list\n",
        "    return list(dict.fromkeys(lst))\n",
        "\n",
        "#Returns the run-length encoded pixels for a filename and given classID from 1 to 4\n",
        "def getEncodedPixels(filename, classID):\n",
        "    return data[filenameAndClassIndex[filename + \"_\" + str(classID)]][1]\n",
        "\n",
        "#Load train.csv as a list\n",
        "trainingDataPath = \"/content/train.csv\"\n",
        "with open(trainingDataPath, 'r') as file:\n",
        "    data = list(csv.reader(file, delimiter=\",\"))\n",
        "\n",
        "filenameAndClassIndex = {} #dictionary to index data array based on first column's value (ImageId_ClassId)   \n",
        "filenames = []\n",
        "\n",
        "for i in range(1, len(data)):\n",
        "    filenameAndClassIndex[data[i][0]] = i\n",
        "    filenames.append(data[i][0].split(\"_\")[0])\n",
        "filenames = removeDuplicates(filenames) # remove duplicates from the list of filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIkrE2Q6M2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def getOneClassFilenames(classID, filenamesByClass):\n",
        "    #gets a list of filenames that are only in one class and not in multiple classes\n",
        "    for i in range(5):\n",
        "        others = set()\n",
        "        if i != classID:\n",
        "            #Get a union of all the image names not in the class\n",
        "            others = others.union(set(filenamesByClass[i]))\n",
        "    return list(set(filenamesByClass[classID]).difference(others)) #only keep the filenames not in others\n",
        "def getImage(filename):\n",
        "    #returns a PIL Image object of the image with name 'filename'\n",
        "    os.chdir(\"/content/train_images\")\n",
        "    picture = Image.open(filename)\n",
        "    return picture"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfFqezwz0Y_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the number of images with defects in each class\n",
        "\n",
        "#numInClassCounter[0] is the number of images w/ no defects, numInClassCounter[1] is the number of images w/ class 1 defects... \n",
        "#filenamesByClass is a 2D list. The first dimension corresponds to the classID (0: No defects, ..., 1: Class 1, 4: Class 4)\n",
        "\n",
        "numClasses = 5\n",
        "numInClassCounter = [0, 0, 0, 0, 0]\n",
        "filenamesByClass = [[], [], [], [], []]\n",
        "for img_file in filenames:\n",
        "    noDefects = True\n",
        "    for classID in range(1,5):\n",
        "        if getEncodedPixels(img_file, classID) != '': \n",
        "              numInClassCounter[classID] += 1 \n",
        "              filenamesByClass[classID].append(img_file)\n",
        "              noDefects = False\n",
        "    if noDefects:\n",
        "        numInClassCounter[0] +=1\n",
        "        filenamesByClass[0].append(img_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys--Emmx6Az3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get a list of filenames which only have 1 class of defect. First dimension is the class, second dimension is the list.\n",
        "#These files will be used to create the histogram\n",
        "uniqueFilenamesByClass = []\n",
        "for i in range(5):\n",
        "    uniqueFilenamesByClass.append(getOneClassFilenames(i, filenamesByClass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53VLyIAr0h7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('content/split/train/')\n",
        "os.makedirs('content/split/train/0')\n",
        "os.makedirs('content/split/train/1')\n",
        "os.makedirs('content/split/validation/0')\n",
        "os.makedirs('content/split/validation/1')\n",
        "os.makedirs('content/split/test/')\n",
        "os.makedirs('content/split/test/0')\n",
        "os.makedirs('content/split/test/1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvBKMbg8DL9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "changeDir= 'content/split/train/0/'\n",
        "trainDir='/content/train_images/'\n",
        "random.seed(1)\n",
        "train0ImageNames, val0ImageNames, test0ImageNames = [], [], []\n",
        "random.shuffle(filenamesByClass[0])\n",
        "\n",
        "train0ImageNames=filenamesByClass[0][:int(0.7*len(filenamesByClass[0]))]\n",
        "val0ImageNames=filenamesByClass[0][int(0.7*len(filenamesByClass[0])):int(0.85*len(filenamesByClass[0]))]\n",
        "test0ImageNames=filenamesByClass[0][int(0.85*len(filenamesByClass[0])):len(filenamesByClass[0])]\n",
        "# put into train folder\n",
        "for i in train0ImageNames:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  os.rename(imgDir, imgchangeDir)\n",
        "# put into validation folder\n",
        "changeDir= 'content/split/validation/0/'\n",
        "for i in val0ImageNames:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  os.rename(imgDir, imgchangeDir)\n",
        "# test folder\n",
        "changeDir= 'content/split/test/0/'\n",
        "for i in test0ImageNames:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  os.rename(imgDir, imgchangeDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdenBnjeDNl4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split into training, validation, and testing set\n",
        "\n",
        "#First split up the filenames randomly. Use a 70-15-15 split within each class, append to the set, and then remove duplicates\n",
        "trainImageNames, valImageNames, testImageNames = [], [], []\n",
        "for i in range(1, numClasses): #1, numClasses if ignoring classes without defects\n",
        "    filesForClass = filenamesByClass[i]\n",
        "    random.seed(1)\n",
        "    random.shuffle(filesForClass)\n",
        "\n",
        "    trainImageNames.append(filesForClass[:int(0.7*len(filesForClass))])\n",
        "    valImageNames.append(filesForClass[int(0.7*len(filesForClass)):int(0.85*len(filesForClass))])\n",
        "    testImageNames.append(filesForClass[int(0.85*len(filesForClass)):len(filesForClass)])\n",
        "\n",
        "#Flatten 2D lists to 1D\n",
        "trainImageNames = list(itertools.chain(*trainImageNames))\n",
        "valImageNames = list(itertools.chain(*valImageNames))\n",
        "testImageNames = list(itertools.chain(*testImageNames))\n",
        "\n",
        "#Remove duplicate names\n",
        "trainImageNames = removeDuplicates(trainImageNames)\n",
        "valImageNames = removeDuplicates(valImageNames)\n",
        "testImageNames = removeDuplicates(testImageNames)\n",
        "\n",
        "#Shuffle again to mix up the classes\n",
        "random.shuffle(trainImageNames)\n",
        "random.shuffle(valImageNames)\n",
        "random.shuffle(testImageNames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJXjZFheDWko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "changeDir= 'content/split/train/1/'\n",
        "trainDir='/content/train_images/'\n",
        "\n",
        "# put into train folder\n",
        "for i in train0ImageNames:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  my_file = Path(imgDir)\n",
        "  if my_file.is_file():\n",
        "      os.rename(imgDir, imgchangeDir)\n",
        "# put into validation folder\n",
        "changeDir= 'content/split/validation/1/'\n",
        "for i in val0ImageNames:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  my_file = Path(imgDir)\n",
        "  if my_file.is_file():\n",
        "      os.rename(imgDir, imgchangeDir)\n",
        "# test folder\n",
        "changeDir= 'content/split/test/1/'\n",
        "for i in test0ImageNames:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  my_file = Path(imgDir)\n",
        "  if my_file.is_file():\n",
        "      os.rename(imgDir, imgchangeDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVWi7vvs1fox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define training and test data directories\n",
        "train_dir = 'content/split/train'\n",
        "val_dir = 'content/split/validation'\n",
        "test_dir = 'content/split/test'\n",
        "\n",
        "# load and transform data using ImageFolder\n",
        "data_transform = transforms.Compose([transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "val_data = datasets.ImageFolder(val_dir, transform=data_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVgg2MjSk7OG",
        "colab_type": "text"
      },
      "source": [
        "# Training AlexNet/CNN Stage 1 with Full Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UlfubNKk5b4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchvision.models\n",
        "alexnet = torchvision.models.alexnet(pretrained=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYetR_mXpknT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "num_workers = 0\n",
        "\n",
        "# create a dataloader\n",
        "train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                       num_workers=num_workers, shuffle=False)\n",
        "# validation dataloader\n",
        "val_data_loader = torch.utils.data.DataLoader(val_data, batch_size=batch_size, \n",
        "                                       num_workers=num_workers, shuffle=False)\n",
        "# testing dataloader\n",
        "test_data_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
        "                                       num_workers=num_workers, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKWKTyjTlwSt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Compute the AlexNet features\n",
        "i = 0\n",
        "for imgs, labels in train_data_loader:\n",
        "    i = i + 1\n",
        "    train_features = alexnet.features(imgs)\n",
        "    torch.save(train_features, 'train_features_' + str(i) + '.pt')\n",
        "\n",
        "i = 0\n",
        "for imgs, labels in val_data_loader:\n",
        "    i = i + 1\n",
        "    val_features = alexnet.features(imgs)\n",
        "    torch.save(val_features, 'val_features_' + str(i) + '.pt')\n",
        "\n",
        "i = 0\n",
        "for imgs, labels in test_data_loader:\n",
        "    i = i + 1\n",
        "    test_features = alexnet.features(imgs)\n",
        "    torch.save(test_features, 'test_features_' + str(i) + '.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cr-XO5OD9SEY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Re-load saved features\n",
        "path = '/content/drive/My Drive/APS360 2019 September Team/Steel Defect Detection/Features'\n",
        "features = os.listdir(path)\n",
        "for feature in features:\n",
        "    shutil.copy(path + feature, \"/content/\" + feature)\n",
        "\n",
        "#Combine train_features back into 1 tensor for training set\n",
        "train_features = torch.load(\"train_features_\" + str(1) + \".pt\")\n",
        "for i in range(1, 2):\n",
        "    train_features = torch.cat([train_features, torch.load(\"train_features_\" + str(i+1) + \".pt\") ], 0)\n",
        "val_features = torch.load(\"val_features_\" + str(1) + \".pt\")\n",
        "test_features = torch.load(\"test_features_\" + str(1) + \".pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pywRiSeImAhH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class alexNet(nn.Module):\n",
        "      def __init__(self):\n",
        "          super(alexNet, self).__init__()\n",
        "          self.name = \"alexNet_precompute\"\n",
        "          self.fc1 = nn.Linear(9216, 800)\n",
        "          self.fc2 = nn.Linear(800, 300)\n",
        "          self.fc3 = nn.Linear(300, 2)\n",
        " \n",
        "      def forward(self, x):\n",
        "          x = x.view(x.size(0), -1) #flatten the input\n",
        "          x = F.relu(self.fc1(x))\n",
        "          x = F.relu(self.fc2(x))\n",
        "          x = self.fc3(x)\n",
        "          x = x.squeeze(1)\n",
        "          return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNo5B7iOmJah",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_trainable_features(alexNetFeatures, image_data):\n",
        "    x = [] \n",
        "    for i, img in enumerate(alexNetFeatures):\n",
        "        x.append((img, image_data[i][1])) #append the image tensor and the label\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eN5OK8njcca",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training\n",
        "train_alexNet = make_trainable_features(train_features, train_data)\n",
        "val_alexNet = make_trainable_features(val_features, val_data)\n",
        "model = alexNet()\n",
        "train(model, train_alexNet, val_alexNet, batch_size=batch_size, num_epochs=50, learning_rate = 0.0001, useGPU = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ifr_ZxvRoZmG",
        "outputId": "13f5169b-e2de-4bb9-d714-8676f6124cf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "# testing \n",
        "get_accuracy(model, test_data_loader, useGPU=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-0c1bd4e3c0ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0museGPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'get_accuracy' is not defined"
          ]
        }
      ]
    }
  ]
}