{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryBaselineSVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhvJvwG2jYuq",
        "colab_type": "text"
      },
      "source": [
        "#Setup and Architecture\n",
        "\n",
        "Here we will find the following sections: \n",
        "   1. Import Section\n",
        "   2. Defining the training/accuracy functions \n",
        "   3. Dataset Generation\n",
        "   4. Training Stage 1 AlexNet model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiikkWY4pyy5",
        "colab_type": "text"
      },
      "source": [
        "#FORMATTING NOTES:\n",
        "\n",
        "1. **Input size for images is:** 224 by 224\n",
        "2. All images should be in greyscale (With channel dimension included)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAr2ALkUn0qI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import Section\n",
        "\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "import scipy.signal as sg\n",
        "from PIL import Image, ImageDraw\n",
        "import requests\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt # for plotting\n",
        "import torch.optim as optim #for gradient descent\n",
        "import torchvision\n",
        "import torch.utils.data as data\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms, utils, models\n",
        "\n",
        "import csv\n",
        "import seaborn as sn\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "from scipy import ndimage, misc\n",
        "import itertools\n",
        "from skimage import io, transform"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ErXBq5GtuR7",
        "colab_type": "text"
      },
      "source": [
        "#20 Samples Import\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFmcZ1Do76y",
        "colab_type": "code",
        "outputId": "20411ba8-721c-49e4-9dc3-0e503f0f4a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaolHbbOn7AC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define training and test data directories\n",
        "#THIS IS DIFFERENT FOR EVERYONE!!!!\n",
        "#  - Emily: '/content/drive/My Drive/20 samples'\n",
        "#  - Hiranya: '/content/drive/My Drive/APS360 2019 September Team/Steel Defect Detection/20 samples'\n",
        "train_dir = '/content/drive/My Drive/APS360 2019 September Team/Steel Defect Detection/20 samples'\n",
        "\n",
        "\n",
        "data_transform = transforms.Compose([transforms.Resize((800,128)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xm2nPPBeuhMV",
        "colab_type": "code",
        "outputId": "c338d5d6-bbec-4b30-9e2e-28fd9e9337f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "print (train_data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ImageFolder\n",
            "    Number of datapoints: 22\n",
            "    Root location: /content/drive/My Drive/APS360 2019 September Team/Steel Defect Detection/20 samples\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               Resize(size=(800, 128), interpolation=PIL.Image.BILINEAR)\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
            "           )\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfznVHN9tzK3",
        "colab_type": "text"
      },
      "source": [
        "#Define Training and Accuracy Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xT312aniuTE9",
        "colab_type": "text"
      },
      "source": [
        "Baseline model training code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eeGPTZbpXiMO",
        "colab": {}
      },
      "source": [
        "def get_accuracy(model, data_loader, useGPU=True):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "        #To Enable GPU Usage\n",
        "        if useGPU and torch.cuda.is_available():\n",
        "            imgs = imgs.cuda()\n",
        "            labels = labels.cuda()\n",
        "            model = model.cuda()\n",
        "        output = model(imgs)\n",
        "        \n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "        \n",
        "    return correct / total"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF5tQuGAnxJi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, train_data, val_data, batch_size=64, num_epochs=1, learning_rate=0.01, useGPU=True):\n",
        "    \n",
        "    #Put data in data loaders\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=0, shuffle=False)\n",
        "    val_data_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
        "                                           num_workers=0, shuffle=False)\n",
        "   \n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), learning_rate)\n",
        "   \n",
        "    iters, losses, train_acc, val_acc = [], [], [], []\n",
        "\n",
        "    if useGPU and torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "        print(\"Training on GPU\")\n",
        "   \n",
        "    # training\n",
        "    n = 0 # the number of iterations\n",
        "    for epoch in range(num_epochs):\n",
        "        for imgs, labels in iter(train_data_loader):\n",
        "          #To Enable GPU Usage\n",
        "          if useGPU and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "          \n",
        "          out = model(imgs)             # forward pass\n",
        "\n",
        "          loss = criterion(out, labels) # compute the total loss\n",
        "          loss.backward()               # backward pass (compute parameter updates)\n",
        "          optimizer.step()              # make the updates for each parameter\n",
        "          optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "          # save the current training information\n",
        "          iters.append(n)\n",
        "          losses.append(float(loss)/batch_size)             # compute *average* loss\n",
        "          train_acc.append(get_accuracy(model, train_data_loader, useGPU)) # compute training accuracy \n",
        "          val_acc.append(get_accuracy(model, val_data_loader, useGPU))  # compute validation accuracy\n",
        "          n += 1\n",
        "        print((\"Epoch {}: Train loss: {}, \"+\"Train accuracy: {}\").format(epoch + 1,losses[epoch],train_acc[epoch]))\n",
        "            \n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(model.name,\n",
        "                                                    batch_size,\n",
        "                                                    str(learning_rate).replace('.', '-'),\n",
        "                                                    epoch)\n",
        "        torch.save(model.state_dict(), model_path + \".pth\")         \n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, losses, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(iters, train_acc, label=\"Train\")\n",
        "    plt.plot(iters, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRODTdcxOnF8",
        "colab_type": "text"
      },
      "source": [
        "# Split train Data into 1 and 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJIpykewm0_",
        "colab_type": "code",
        "outputId": "1e3adb13-2a0d-48db-b215-7c3e1e73d3fb",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7Ci8vIE1heCBhbW91bnQgb2YgdGltZSB0byBibG9jayB3YWl0aW5nIGZvciB0aGUgdXNlci4KY29uc3QgRklMRV9DSEFOR0VfVElNRU9VVF9NUyA9IDMwICogMTAwMDsKCmZ1bmN0aW9uIF91cGxvYWRGaWxlcyhpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IHN0ZXBzID0gdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKTsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIC8vIENhY2hlIHN0ZXBzIG9uIHRoZSBvdXRwdXRFbGVtZW50IHRvIG1ha2UgaXQgYXZhaWxhYmxlIGZvciB0aGUgbmV4dCBjYWxsCiAgLy8gdG8gdXBsb2FkRmlsZXNDb250aW51ZSBmcm9tIFB5dGhvbi4KICBvdXRwdXRFbGVtZW50LnN0ZXBzID0gc3RlcHM7CgogIHJldHVybiBfdXBsb2FkRmlsZXNDb250aW51ZShvdXRwdXRJZCk7Cn0KCi8vIFRoaXMgaXMgcm91Z2hseSBhbiBhc3luYyBnZW5lcmF0b3IgKG5vdCBzdXBwb3J0ZWQgaW4gdGhlIGJyb3dzZXIgeWV0KSwKLy8gd2hlcmUgdGhlcmUgYXJlIG11bHRpcGxlIGFzeW5jaHJvbm91cyBzdGVwcyBhbmQgdGhlIFB5dGhvbiBzaWRlIGlzIGdvaW5nCi8vIHRvIHBvbGwgZm9yIGNvbXBsZXRpb24gb2YgZWFjaCBzdGVwLgovLyBUaGlzIHVzZXMgYSBQcm9taXNlIHRvIGJsb2NrIHRoZSBweXRob24gc2lkZSBvbiBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcCwKLy8gdGhlbiBwYXNzZXMgdGhlIHJlc3VsdCBvZiB0aGUgcHJldmlvdXMgc3RlcCBhcyB0aGUgaW5wdXQgdG8gdGhlIG5leHQgc3RlcC4KZnVuY3Rpb24gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpIHsKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIGNvbnN0IHN0ZXBzID0gb3V0cHV0RWxlbWVudC5zdGVwczsKCiAgY29uc3QgbmV4dCA9IHN0ZXBzLm5leHQob3V0cHV0RWxlbWVudC5sYXN0UHJvbWlzZVZhbHVlKTsKICByZXR1cm4gUHJvbWlzZS5yZXNvbHZlKG5leHQudmFsdWUucHJvbWlzZSkudGhlbigodmFsdWUpID0+IHsKICAgIC8vIENhY2hlIHRoZSBsYXN0IHByb21pc2UgdmFsdWUgdG8gbWFrZSBpdCBhdmFpbGFibGUgdG8gdGhlIG5leHQKICAgIC8vIHN0ZXAgb2YgdGhlIGdlbmVyYXRvci4KICAgIG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSA9IHZhbHVlOwogICAgcmV0dXJuIG5leHQudmFsdWUucmVzcG9uc2U7CiAgfSk7Cn0KCi8qKgogKiBHZW5lcmF0b3IgZnVuY3Rpb24gd2hpY2ggaXMgY2FsbGVkIGJldHdlZW4gZWFjaCBhc3luYyBzdGVwIG9mIHRoZSB1cGxvYWQKICogcHJvY2Vzcy4KICogQHBhcmFtIHtzdHJpbmd9IGlucHV0SWQgRWxlbWVudCBJRCBvZiB0aGUgaW5wdXQgZmlsZSBwaWNrZXIgZWxlbWVudC4KICogQHBhcmFtIHtzdHJpbmd9IG91dHB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIG91dHB1dCBkaXNwbGF5LgogKiBAcmV0dXJuIHshSXRlcmFibGU8IU9iamVjdD59IEl0ZXJhYmxlIG9mIG5leHQgc3RlcHMuCiAqLwpmdW5jdGlvbiogdXBsb2FkRmlsZXNTdGVwKGlucHV0SWQsIG91dHB1dElkKSB7CiAgY29uc3QgaW5wdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQoaW5wdXRJZCk7CiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gZmFsc2U7CgogIGNvbnN0IG91dHB1dEVsZW1lbnQgPSBkb2N1bWVudC5nZXRFbGVtZW50QnlJZChvdXRwdXRJZCk7CiAgb3V0cHV0RWxlbWVudC5pbm5lckhUTUwgPSAnJzsKCiAgY29uc3QgcGlja2VkUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBpbnB1dEVsZW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignY2hhbmdlJywgKGUpID0+IHsKICAgICAgcmVzb2x2ZShlLnRhcmdldC5maWxlcyk7CiAgICB9KTsKICB9KTsKCiAgY29uc3QgY2FuY2VsID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnYnV0dG9uJyk7CiAgaW5wdXRFbGVtZW50LnBhcmVudEVsZW1lbnQuYXBwZW5kQ2hpbGQoY2FuY2VsKTsKICBjYW5jZWwudGV4dENvbnRlbnQgPSAnQ2FuY2VsIHVwbG9hZCc7CiAgY29uc3QgY2FuY2VsUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICBjYW5jZWwub25jbGljayA9ICgpID0+IHsKICAgICAgcmVzb2x2ZShudWxsKTsKICAgIH07CiAgfSk7CgogIC8vIENhbmNlbCB1cGxvYWQgaWYgdXNlciBoYXNuJ3QgcGlja2VkIGFueXRoaW5nIGluIHRpbWVvdXQuCiAgY29uc3QgdGltZW91dFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgc2V0VGltZW91dCgoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9LCBGSUxFX0NIQU5HRV9USU1FT1VUX01TKTsKICB9KTsKCiAgLy8gV2FpdCBmb3IgdGhlIHVzZXIgdG8gcGljayB0aGUgZmlsZXMuCiAgY29uc3QgZmlsZXMgPSB5aWVsZCB7CiAgICBwcm9taXNlOiBQcm9taXNlLnJhY2UoW3BpY2tlZFByb21pc2UsIHRpbWVvdXRQcm9taXNlLCBjYW5jZWxQcm9taXNlXSksCiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdzdGFydGluZycsCiAgICB9CiAgfTsKCiAgaWYgKCFmaWxlcykgewogICAgcmV0dXJuIHsKICAgICAgcmVzcG9uc2U6IHsKICAgICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICAgIH0KICAgIH07CiAgfQoKICBjYW5jZWwucmVtb3ZlKCk7CgogIC8vIERpc2FibGUgdGhlIGlucHV0IGVsZW1lbnQgc2luY2UgZnVydGhlciBwaWNrcyBhcmUgbm90IGFsbG93ZWQuCiAgaW5wdXRFbGVtZW50LmRpc2FibGVkID0gdHJ1ZTsKCiAgZm9yIChjb25zdCBmaWxlIG9mIGZpbGVzKSB7CiAgICBjb25zdCBsaSA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2xpJyk7CiAgICBsaS5hcHBlbmQoc3BhbihmaWxlLm5hbWUsIHtmb250V2VpZ2h0OiAnYm9sZCd9KSk7CiAgICBsaS5hcHBlbmQoc3BhbigKICAgICAgICBgKCR7ZmlsZS50eXBlIHx8ICduL2EnfSkgLSAke2ZpbGUuc2l6ZX0gYnl0ZXMsIGAgKwogICAgICAgIGBsYXN0IG1vZGlmaWVkOiAkewogICAgICAgICAgICBmaWxlLmxhc3RNb2RpZmllZERhdGUgPyBmaWxlLmxhc3RNb2RpZmllZERhdGUudG9Mb2NhbGVEYXRlU3RyaW5nKCkgOgogICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAnbi9hJ30gLSBgKSk7CiAgICBjb25zdCBwZXJjZW50ID0gc3BhbignMCUgZG9uZScpOwogICAgbGkuYXBwZW5kQ2hpbGQocGVyY2VudCk7CgogICAgb3V0cHV0RWxlbWVudC5hcHBlbmRDaGlsZChsaSk7CgogICAgY29uc3QgZmlsZURhdGFQcm9taXNlID0gbmV3IFByb21pc2UoKHJlc29sdmUpID0+IHsKICAgICAgY29uc3QgcmVhZGVyID0gbmV3IEZpbGVSZWFkZXIoKTsKICAgICAgcmVhZGVyLm9ubG9hZCA9IChlKSA9PiB7CiAgICAgICAgcmVzb2x2ZShlLnRhcmdldC5yZXN1bHQpOwogICAgICB9OwogICAgICByZWFkZXIucmVhZEFzQXJyYXlCdWZmZXIoZmlsZSk7CiAgICB9KTsKICAgIC8vIFdhaXQgZm9yIHRoZSBkYXRhIHRvIGJlIHJlYWR5LgogICAgbGV0IGZpbGVEYXRhID0geWllbGQgewogICAgICBwcm9taXNlOiBmaWxlRGF0YVByb21pc2UsCiAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgYWN0aW9uOiAnY29udGludWUnLAogICAgICB9CiAgICB9OwoKICAgIC8vIFVzZSBhIGNodW5rZWQgc2VuZGluZyB0byBhdm9pZCBtZXNzYWdlIHNpemUgbGltaXRzLiBTZWUgYi82MjExNTY2MC4KICAgIGxldCBwb3NpdGlvbiA9IDA7CiAgICB3aGlsZSAocG9zaXRpb24gPCBmaWxlRGF0YS5ieXRlTGVuZ3RoKSB7CiAgICAgIGNvbnN0IGxlbmd0aCA9IE1hdGgubWluKGZpbGVEYXRhLmJ5dGVMZW5ndGggLSBwb3NpdGlvbiwgTUFYX1BBWUxPQURfU0laRSk7CiAgICAgIGNvbnN0IGNodW5rID0gbmV3IFVpbnQ4QXJyYXkoZmlsZURhdGEsIHBvc2l0aW9uLCBsZW5ndGgpOwogICAgICBwb3NpdGlvbiArPSBsZW5ndGg7CgogICAgICBjb25zdCBiYXNlNjQgPSBidG9hKFN0cmluZy5mcm9tQ2hhckNvZGUuYXBwbHkobnVsbCwgY2h1bmspKTsKICAgICAgeWllbGQgewogICAgICAgIHJlc3BvbnNlOiB7CiAgICAgICAgICBhY3Rpb246ICdhcHBlbmQnLAogICAgICAgICAgZmlsZTogZmlsZS5uYW1lLAogICAgICAgICAgZGF0YTogYmFzZTY0LAogICAgICAgIH0sCiAgICAgIH07CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPQogICAgICAgICAgYCR7TWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCl9JSBkb25lYDsKICAgIH0KICB9CgogIC8vIEFsbCBkb25lLgogIHlpZWxkIHsKICAgIHJlc3BvbnNlOiB7CiAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgIH0KICB9Owp9CgpzY29wZS5nb29nbGUgPSBzY29wZS5nb29nbGUgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYiA9IHNjb3BlLmdvb2dsZS5jb2xhYiB8fCB7fTsKc2NvcGUuZ29vZ2xlLmNvbGFiLl9maWxlcyA9IHsKICBfdXBsb2FkRmlsZXMsCiAgX3VwbG9hZEZpbGVzQ29udGludWUsCn07Cn0pKHNlbGYpOwo=",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "#Link to competition: https://www.kaggle.com/c/severstal-steel-defect-detection/overview\n",
        "#Upload the Kaggle JSON file (download it from the drive to your computer first)\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d5398aaf-771b-420f-bf6a-2a6d43fa9c79\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-d5398aaf-771b-420f-bf6a-2a6d43fa9c79\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"farhanwadia\",\"key\":\"2c92598698ee94f469567eb3af100ca4\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9f4PxF5wnvW",
        "colab_type": "code",
        "outputId": "c525c44a-1f80-434d-ce48-678b4e2bbe77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Mount the kaggle.json file\n",
        "!ls -lha kaggle.json\n",
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 67 Nov 21 02:56 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188R2ubXw3ai",
        "colab_type": "code",
        "outputId": "fba0af72-c2a4-4483-f8f5-a0c622de09e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Extract required files\n",
        "!kaggle competitions download -c severstal-steel-defect-detection -q\n",
        "!unzip -q train.csv.zip\n",
        "!unzip -q train_images.zip -d train_images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOR3DErY0WW0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Load the dataset and list of filenames\n",
        "\n",
        "def removeDuplicates(lst):\n",
        "    #Remove duplicate values from a list\n",
        "    return list(dict.fromkeys(lst))\n",
        "\n",
        "#Returns the run-length encoded pixels for a filename and given classID from 1 to 4\n",
        "def getEncodedPixels(filename, classID):\n",
        "    return data[filenameAndClassIndex[filename + \"_\" + str(classID)]][1]\n",
        "\n",
        "#Load train.csv as a list\n",
        "trainingDataPath = \"/content/train.csv\"\n",
        "with open(trainingDataPath, 'r') as file:\n",
        "    data = list(csv.reader(file, delimiter=\",\"))\n",
        "\n",
        "filenameAndClassIndex = {} #dictionary to index data array based on first column's value (ImageId_ClassId)   \n",
        "filenames = []\n",
        "\n",
        "for i in range(1, len(data)):\n",
        "    filenameAndClassIndex[data[i][0]] = i\n",
        "    filenames.append(data[i][0].split(\"_\")[0])\n",
        "filenames = removeDuplicates(filenames) # remove duplicates from the list of filenames"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIkrE2Q6M2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getOneClassFilenames(classID, filenamesByClass):\n",
        "    #gets a list of filenames that are only in one class and not in multiple classes\n",
        "    for i in range(5):\n",
        "        others = set()\n",
        "        if i != classID:\n",
        "            #Get a union of all the image names not in the class\n",
        "            others = others.union(set(filenamesByClass[i]))\n",
        "    return list(set(filenamesByClass[classID]).difference(others)) #only keep the filenames not in others\n",
        "def getImage(filename):\n",
        "    #returns a PIL Image object of the image with name 'filename'\n",
        "    os.chdir(\"/content/train_images\")\n",
        "    picture = Image.open(filename)\n",
        "    return picture"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfFqezwz0Y_A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get the number of images with defects in each class\n",
        "\n",
        "#numInClassCounter[0] is the number of images w/ no defects, numInClassCounter[1] is the number of images w/ class 1 defects... \n",
        "#filenamesByClass is a 2D list. The first dimension corresponds to the classID (0: No defects, ..., 1: Class 1, 4: Class 4)\n",
        "\n",
        "numClasses = 5\n",
        "numInClassCounter = [0, 0, 0, 0, 0]\n",
        "filenamesByClass = [[], [], [], [], []]\n",
        "for img_file in filenames:\n",
        "    noDefects = True\n",
        "    for classID in range(1,5):\n",
        "        if getEncodedPixels(img_file, classID) != '': \n",
        "              numInClassCounter[classID] += 1 \n",
        "              filenamesByClass[classID].append(img_file)\n",
        "              noDefects = False\n",
        "    if noDefects:\n",
        "        numInClassCounter[0] +=1\n",
        "        filenamesByClass[0].append(img_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ys--Emmx6Az3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get a list of filenames which only have 1 class of defect. First dimension is the class, second dimension is the list.\n",
        "#These files will be used to create the histogram\n",
        "uniqueFilenamesByClass = []\n",
        "for i in range(5):\n",
        "    uniqueFilenamesByClass.append(getOneClassFilenames(i, filenamesByClass))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53VLyIAr0h7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('content/split/0')\n",
        "changeDir= 'content/split/0/'\n",
        "trainDir='/content/train_images/'\n",
        "for i in uniqueFilenamesByClass[0]:\n",
        "  imgDir=trainDir+i\n",
        "  imgchangeDir=changeDir + i\n",
        "  os.rename(imgDir, imgchangeDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEPZJrlA0ia4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pV4kM1mQ0q3y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('content/split/1')\n",
        "changeDir= 'content/split/1/'\n",
        "trainDir='/content/train_images/'\n",
        "for j in range(1,5):\n",
        "  for i in uniqueFilenamesByClass[j]:\n",
        "    imgDir=trainDir+i\n",
        "    imgchangeDir=changeDir + i\n",
        "    my_file = Path(imgDir)\n",
        "    if my_file.is_file():\n",
        "      os.rename(imgDir, imgchangeDir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVWi7vvs1fox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define training and test data directories\n",
        "train_dir = 'content/split/'\n",
        "\n",
        "# load and transform data using ImageFolder\n",
        "data_transform = transforms.Compose([transforms.Resize((800,128)),transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
        "\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7sp45ry5DO-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Include all import statements required over here\n",
        "import csv\n",
        "import numpy as np\n",
        "np.set_printoptions(suppress=True)\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sn\n",
        "from PIL import Image, ImageDraw\n",
        "import math\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import cv2\n",
        "from scipy import ndimage, misc\n",
        "import itertools\n",
        "from skimage import io, transform\n",
        "from sklearn import svm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms, utils, models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv7PrL-RMTkl",
        "colab_type": "code",
        "outputId": "661e4a98-e21b-4918-8d05-0261fa8ddccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.shape(train_data.targets))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(12568,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DedKjB1EJTKI",
        "colab_type": "code",
        "outputId": "2e33475a-6523-44aa-9817-b5103b0505b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "BaselineSVM = svm.NuSVC(gamma = 'scale')\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size = 64, shuffle = True)\n",
        "counter = 0\n",
        "accuracy = []\n",
        "\n",
        "for imgs, labels in iter(train_loader):\n",
        "  floatLabels =  labels.float() \n",
        "  #print(imgs)\n",
        "  #print(floatLabels)\n",
        "  imgs = imgs.view(-1, 800 * 128 *3)\n",
        "\n",
        "  BaselineSVM.fit(imgs, floatLabels)\n",
        "  accuracy.append(BaselineSVM.score(imgs, floatLabels)) \n",
        "  print('Accuracy of binary baseline SVM for batch: ', counter,' is: ', accuracy[counter])\n",
        "\n",
        "  counter = counter +1\n",
        "\n",
        "#np.random.shuffle(training_images)\n",
        "#np.random.shuffle(training_Targets)\n",
        "\n",
        "#print(training_images_locations)\n",
        "#print(training_Targets)\n",
        "\n",
        "total = sum(accuracy)\n",
        "averageAcc = total/counter\n",
        "print('Average accuracy per batch is: ', averageAcc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of binary baseline SVM for batch:  0  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  1  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  2  is:  0.90625\n",
            "Accuracy of binary baseline SVM for batch:  3  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  4  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  5  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  6  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  7  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  8  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  9  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  10  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  11  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  12  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  13  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  14  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  15  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  16  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  17  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  18  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  19  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  20  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  21  is:  0.90625\n",
            "Accuracy of binary baseline SVM for batch:  22  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  23  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  24  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  25  is:  1.0\n",
            "Accuracy of binary baseline SVM for batch:  26  is:  0.90625\n",
            "Accuracy of binary baseline SVM for batch:  27  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  28  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  29  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  30  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  31  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  32  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  33  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  34  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  35  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  36  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  37  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  38  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  39  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  40  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  41  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  42  is:  0.90625\n",
            "Accuracy of binary baseline SVM for batch:  43  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  44  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  45  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  46  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  47  is:  1.0\n",
            "Accuracy of binary baseline SVM for batch:  48  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  49  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  50  is:  1.0\n",
            "Accuracy of binary baseline SVM for batch:  51  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  52  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  53  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  54  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  55  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  56  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  57  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  58  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  59  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  60  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  61  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  62  is:  0.875\n",
            "Accuracy of binary baseline SVM for batch:  63  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  64  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  65  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  66  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  67  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  68  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  69  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  70  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  71  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  72  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  73  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  74  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  75  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  76  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  77  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  78  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  79  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  80  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  81  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  82  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  83  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  84  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  85  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  86  is:  0.90625\n",
            "Accuracy of binary baseline SVM for batch:  87  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  88  is:  1.0\n",
            "Accuracy of binary baseline SVM for batch:  89  is:  0.9375\n",
            "Accuracy of binary baseline SVM for batch:  90  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  91  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  92  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  93  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  94  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  95  is:  0.953125\n",
            "Accuracy of binary baseline SVM for batch:  96  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  97  is:  0.921875\n",
            "Accuracy of binary baseline SVM for batch:  98  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  99  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  100  is:  0.984375\n",
            "Accuracy of binary baseline SVM for batch:  101  is:  0.96875\n",
            "Accuracy of binary baseline SVM for batch:  102  is:  0.96875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}